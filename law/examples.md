= examples

ChatGPT 对简单直接要求作恶的提问，可以较好的识别过滤。比如，用户直接要求编写钓鱼邮件，会被直接拒绝：

![](/images/law/email.jpeg)

ChatGPT 对一些知名的文学和影视作品，有较好的认知，可以识别过滤掉明显的针对知名虚拟人物的二次创作要求。比如，用户要求对奥特曼进行二次创作时，ChatGPT 会申明自己知道奥特曼的存在并努力引导到实际存在的奥特曼剧集人物中：

![](/images/law/ultraman.png)

从对话中可以看出，ChatGPT 不光是毫不伪装的直接给出了著名的迪迦、戴拿、盖亚，甚至一开始还谨慎的声明了自己反对提问者用"老人"这个词所反映出的潜在的年龄偏见。

ChatGPT 对政治话题也有一定的识别过滤能力。但政治本身是有立场的，很可惜，目前 ChatGPT 作为由美国硅谷创业公司研究出来的产品，在政治话题过滤方面，和多数硅谷 IT 公司一样，明显站队在美国民主党立场。

例如，在美国历任民主党总统和共和党总统之间，ChatGPT 表现出截然不同的态度：

![](/images/law/usa-president.png)

在 ChatGPT 公测初期，部分技术极客从测试的角度，发现了不少绕过 ChatGPT 内容过滤机制的提示语扮演方案，人们形象的称之为"越狱(jailbreaking)"。 各种 ChatGPT 越狱案例非常多，几乎每次都能上新闻，本书就不再摘抄这些过时案例。openai 公司人工智能政策研究员Sandhini Agarwal甚至在接收采访时表示：虽然在发布之前就已经做了大量的红队测试，但"越狱"依然是公司当前最需要解决的问题。每次发现新的案例，都会赶紧加入针对性的对抗性训练。

可以说，ChatGPT，乃至未来其他国内外厂商的 LLM 大语言模型服务，都会面临相同的问题：持续训练和维护一个内容过滤模型，比一次性训练出一个内容生成模型，更加重要。

